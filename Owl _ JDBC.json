{"paragraphs":[{"title":"MySql","text":"var props = new java.util.Properties()\nprops.setProperty(\"driver\", \"com.mysql.jdbc.Driver\")\nprops.setProperty(\"user\", \"datalakeadmin\")\nprops.setProperty(\"password\", \"datalakepassword\")\n    \n\nval ds = spark.read.jdbc(\n  url=\"jdbc:mysql://owldatalake.chzid9w0hpyi.us-east-1.rds.amazonaws.com:3306\",\n  table=s\"(select * from silo.account limit 10) abc\",\n  properties=props )\n  \nds.show","user":"anonymous","dateUpdated":"2018-11-02T20:53:18-0400","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.lang.NullPointerException\n\tat org.apache.zeppelin.spark.Utils.invokeMethod(Utils.java:38)\n\tat org.apache.zeppelin.spark.Utils.invokeMethod(Utils.java:33)\n\tat org.apache.zeppelin.spark.SparkInterpreter.createSparkContext_2(SparkInterpreter.java:398)\n\tat org.apache.zeppelin.spark.SparkInterpreter.createSparkContext(SparkInterpreter.java:387)\n\tat org.apache.zeppelin.spark.SparkInterpreter.getSparkContext(SparkInterpreter.java:146)\n\tat org.apache.zeppelin.spark.SparkInterpreter.open(SparkInterpreter.java:843)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.open(LazyOpenInterpreter.java:70)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:491)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:175)\n\tat org.apache.zeppelin.scheduler.FIFOScheduler$1.run(FIFOScheduler.java:139)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n"}]},"apps":[],"jobName":"paragraph_1530322462519_-799751907","id":"20180629-213422_1433152201","dateCreated":"2018-06-29T21:34:22-0400","dateStarted":"2018-11-02T20:53:18-0400","dateFinished":"2018-11-02T20:53:23-0400","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:11030"},{"title":"Oracle Cloud","text":"var props = new java.util.Properties()\nprops.setProperty(\"driver\", \"oracle.jdbc.OracleDriver\")\n//props.setProperty(\"user\", \"brian.mearns@gmail.com\")\n//props.setProperty(\"password\", \"XzRusKly1_\")\n//props.setProperty(\"user\", \"owltestcase\")\n//props.setProperty(\"password\", \"XzRusKly1_\")\n\n//com.driver.OracleDriver  tar -xvf  ojdbc8.jar and ucp list contents find driver\n    \nval ds = spark.read.jdbc(\n  url=\"jdbc:oracle:thin:hr/hr@129.150.90.82:1521:ORCL\",\n//url= \"jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(HOST=129.150.90.82)(PORT=1521)(PROTOCOL=tcp))(CONNECT_DATA=(SERVICE_NAME=PDB1.idcs-70beef90495f42ea809738839d7e4ce0.oraclecloud.internal)))\",\n  table=s\"(select * from user_tables) user_tables\",\n  properties=props )\n  \nds.show","user":"anonymous","dateUpdated":"2018-11-02T20:54:22-0400","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true,"tableHide":false,"editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.lang.NullPointerException\n\tat org.apache.zeppelin.spark.Utils.invokeMethod(Utils.java:38)\n\tat org.apache.zeppelin.spark.Utils.invokeMethod(Utils.java:33)\n\tat org.apache.zeppelin.spark.SparkInterpreter.createSparkContext_2(SparkInterpreter.java:398)\n\tat org.apache.zeppelin.spark.SparkInterpreter.createSparkContext(SparkInterpreter.java:387)\n\tat org.apache.zeppelin.spark.SparkInterpreter.getSparkContext(SparkInterpreter.java:146)\n\tat org.apache.zeppelin.spark.SparkInterpreter.open(SparkInterpreter.java:843)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.open(LazyOpenInterpreter.java:70)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:491)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:175)\n\tat org.apache.zeppelin.scheduler.FIFOScheduler$1.run(FIFOScheduler.java:139)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n"}]},"apps":[],"jobName":"paragraph_1530322747352_1809998238","id":"20180629-213907_1943117521","dateCreated":"2018-06-29T21:39:07-0400","dateStarted":"2018-11-02T20:54:22-0400","dateFinished":"2018-11-02T20:54:23-0400","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:11031"},{"title":"Teradata","text":"var props = new java.util.Properties()\nprops.setProperty(\"driver\", \"com.teradata.jdbc.TeraDriver\")\nprops.setProperty(\"user\", \"datalakeadmin\")\nprops.setProperty(\"password\", \"datalakepassword\")\n\n// need both terajdbc4.jar AND tdgssconfig.jar\n// teradata 17 sip_support=on, MAYBENULL=on, COL_NAME=on, works back to server 14.  \n// LOGMECH=LDAP,SIP_SUPPORT=ON,COLUMN_NAME=ON,MAYBENULL=ON\n    \nval ds = spark.read.jdbc(\n  url=\"jdbc:teradata:localhost:1521\",\n  table=s\"(select * from silo.account limit 10) abc\",\n  properties=props )\n  \nds.show","user":"anonymous","dateUpdated":"2018-07-12T11:44:57-0400","config":{"colWidth":6,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true,"editorHide":false,"tableHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"props: java.util.Properties = {}\nres0: Object = null\nres1: Object = null\nres2: Object = null\njava.lang.ClassNotFoundException: com.teradata.jdbc.TeraDriver\n  at scala.reflect.internal.util.AbstractFileClassLoader.findClass(AbstractFileClassLoader.scala:62)\n  at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n  at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n  at org.apache.spark.sql.execution.datasources.jdbc.DriverRegistry$.register(DriverRegistry.scala:38)\n  at org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions$$anonfun$6.apply(JDBCOptions.scala:78)\n  at org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions$$anonfun$6.apply(JDBCOptions.scala:78)\n  at scala.Option.foreach(Option.scala:257)\n  at org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:78)\n  at org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:34)\n  at org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:32)\n  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:330)\n  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)\n  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:125)\n  at org.apache.spark.sql.DataFrameReader.jdbc(DataFrameReader.scala:166)\n  ... 46 elided\n"}]},"apps":[],"jobName":"paragraph_1530323544048_-596702487","id":"20180629-215224_976977910","dateCreated":"2018-06-29T21:52:24-0400","dateStarted":"2018-07-12T11:44:57-0400","dateFinished":"2018-07-12T11:45:11-0400","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:11032"},{"title":"Oracle Server 12 - Client 8","text":"// TNSNames.ORA  is where all the connection info lives.  grep | TNSNames.ORA\nvar props = new java.util.Properties()\nprops.setProperty(\"driver\", \"oracle.jdbc.OracleDriver\")\nprops.setProperty(\"user\", \"SYSTEM\")\nprops.setProperty(\"password\", \"Ach1z0#d\")\n\n//com.driver.OracleDriver  tar -xvf  ojdbc8.jar and ucp list contents find driver\n    \nval ds = spark.read.jdbc(\n  url=\"jdbc:oracle:thin:@129.158.83.166:1521:ORCL\",\n  table=s\"(select * from user_tables) test \",\n  properties=props )\n  \nval persons = spark.read.jdbc(\n  url=\"jdbc:oracle:thin:@129.158.83.166:1521:ORCL\",\n  table=s\"(select * from PERSONS) persons \",\n  properties=props )\n  \n//ds.show\npersons.show\n","user":"anonymous","dateUpdated":"2018-07-01T21:56:31-0400","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"props: java.util.Properties = {}\nres58: Object = null\nres59: Object = null\nres60: Object = null\nds: org.apache.spark.sql.DataFrame = [TABLE_NAME: string, TABLESPACE_NAME: string ... 62 more fields]\npersons: org.apache.spark.sql.DataFrame = [PERSON_ID: decimal(38,10), FIRST_NAME: string ... 1 more field]\n+------------+----------+---------+\n|   PERSON_ID|FIRST_NAME|LAST_NAME|\n+------------+----------+---------+\n|1.0000000000|      kirk| haslbeck|\n|2.0000000000|     brian|   mearns|\n|3.0000000000|       dan|     rice|\n|4.0000000000|     geoff| gettings|\n+------------+----------+---------+\n\n"}]},"apps":[],"jobName":"paragraph_1530323671657_-249088696","id":"20180629-215431_779320833","dateCreated":"2018-06-29T21:54:31-0400","dateStarted":"2018-07-01T21:59:05-0400","dateFinished":"2018-07-01T21:59:09-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11033"},{"text":"%sh\ngrep | *TNSNames.ORA","user":"anonymous","dateUpdated":"2018-07-01T21:56:31-0400","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"bash: *TNSNames.ORA: command not found\nusage: grep [-abcDEFGHhIiJLlmnOoqRSsUVvwxZ] [-A num] [-B num] [-C[num]]\n\t[-e pattern] [-f file] [--binary-files=value] [--color=when]\n\t[--context[=num]] [--directories=action] [--label] [--line-buffered]\n\t[--null] [pattern] [file ...]\n"},{"type":"TEXT","data":"ExitValue: 127"}]},"apps":[],"jobName":"paragraph_1530453240030_-283958649","id":"20180701-095400_1730053976","dateCreated":"2018-07-01T09:54:00-0400","dateStarted":"2018-07-01T21:56:31-0400","dateFinished":"2018-07-01T21:56:32-0400","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:11034"},{"title":"Phoenix HBase AWS","text":"var props = new java.util.Properties()\nprops.setProperty(\"driver\", \"org.apache.phoenix.jdbc.PhoenixDriver\")\nprops.setProperty(\"user\", \"phoenixuser\")\nprops.setProperty(\"password\", \"phoenixpassword\")\n\n    \nval ds = spark.read.jdbc(\n  url=\"jdbc:phoenix:ec2-52-90-92-34.compute-1.amazonaws.com:2181:/hbase\",\n  table=s\"(select * from APP_CONFIG) test \",\n  properties=props )\n  \n ds.show","user":"anonymous","dateUpdated":"2018-07-07T17:25:48-0400","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"props: java.util.Properties = {}\nres38: Object = null\nres39: Object = null\nres40: Object = null\nds: org.apache.spark.sql.DataFrame = [COL_NM: string, COL_VALUE: string]\n+-------------+---------+\n|       COL_NM|COL_VALUE|\n+-------------+---------+\n|    BASE_PATH|    /opt/|\n|ZEPPELIN_PORT|     9091|\n+-------------+---------+\n\n"}]},"apps":[],"jobName":"paragraph_1530496591081_-455522042","id":"20180701-215631_1982660853","dateCreated":"2018-07-01T21:56:31-0400","dateStarted":"2018-07-07T17:25:48-0400","dateFinished":"2018-07-07T17:25:49-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11035"},{"title":"HIVE JDBC AMAZON","text":"var props = new java.util.Properties()\nprops.setProperty(\"driver\", \"com.amazon.hive.jdbc4.HS2Driver\")\nprops.setProperty(\"user\", \"hive\")\nprops.setProperty(\"password\", \"hive\")\nprops.setProperty(\"hive.resultset.use.unique.column.names\",\"false\")\n\n\n// need both amazon emr drivers from http://awssupportdatasvcs.com/bootstrap-actions/Simba/AmazonHiveJDBC-1.0.9.1060.zip\n    \nval ds = spark.read.jdbc(\n  url=\"jdbc:hive2://ec2-54-85-25-230.compute-1.amazonaws.com:10000/default\",\n  table=s\"(select * from test_history) abc\",\n  properties=props )\n \n//ds.count\nds.printSchema \nds.show","user":"anonymous","dateUpdated":"2018-09-18T09:42:06-0400","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"props: java.util.Properties = {}\nres200: Object = null\nres201: Object = null\nres202: Object = null\nres203: Object = null\nds: org.apache.spark.sql.DataFrame = [exch: string, tick: string ... 7 more fields]\nroot\n |-- exch: string (nullable = true)\n |-- tick: string (nullable = true)\n |-- trade_date: date (nullable = true)\n |-- part_date_str: string (nullable = true)\n |-- open: double (nullable = true)\n |-- high: double (nullable = true)\n |-- low: double (nullable = true)\n |-- close: double (nullable = true)\n |-- volume: double (nullable = true)\n\n+----+-----+----------+-------------+------+------+-----+---------+------+\n|exch| tick|trade_date|part_date_str|  open|  high|  low|    close|volume|\n+----+-----+----------+-------------+------+------+-----+---------+------+\n|NYSE|    A|2015-01-09|           41|  41.0| 40.29|40.59|1644900.0|  null|\n|NYSE|   AA|2015-01-09|        48.09| 48.45| 47.25|48.33|1.67322E7|  null|\n|NYSE|  AAC|2015-01-09|        29.38|  30.4| 28.83|30.13|  71200.0|  null|\n|NYSE|  AAN|2015-01-09|        30.62| 30.73| 30.08|30.37|1069400.0|  null|\n|NYSE|  AAP|2015-01-09|       159.95|161.62|158.39|160.3| 912200.0|  null|\n|NYSE|  AAT|2015-01-09|        42.11| 42.41| 41.84|42.25| 125900.0|  null|\n|NYSE|  AAV|2015-01-09|         4.51|  4.61|  4.43| 4.59| 178500.0|  null|\n|NYSE|   AB|2015-01-09|        25.55| 25.75|  25.2|25.61| 203400.0|  null|\n|NYSE|  ABB|2015-01-09|        20.04| 20.16| 19.94|20.09|1626500.0|  null|\n|NYSE| ABBV|2015-01-09|        66.69|  67.2| 65.11|65.78|8779900.0|  null|\n|NYSE|  ABC|2015-01-09|        92.44| 93.27| 92.32| 93.0|1553600.0|  null|\n|NYSE| ABEV|2015-01-09|         6.24|  6.33|  6.22| 6.28|1.47048E7|  null|\n|NYSE|  ABG|2015-01-09|        75.29| 75.44| 74.35|74.45| 207000.0|  null|\n|NYSE|  ABM|2015-01-09|        29.52| 29.96| 29.14|29.27| 250300.0|  null|\n|NYSE|  ABR|2015-01-09|            7|  7.04|  6.95| 6.97|  91100.0|  null|\n|NYSE|ABR-A|2015-01-09|        25.19| 25.23| 25.18|25.23|   2000.0|  null|\n|NYSE|ABR-B|2015-01-09|         24.8|  24.8| 24.77|24.77|    600.0|  null|\n|NYSE|ABR-C|2015-01-09|        25.48| 25.79| 25.48|25.79|    500.0|  null|\n|NYSE| ABRN|2015-01-09|        25.04| 25.04| 24.96|24.96|    900.0|  null|\n|NYSE|  ABT|2015-01-09|        45.75| 45.87| 45.11| 45.2|4742400.0|  null|\n+----+-----+----------+-------------+------+------+-----+---------+------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1530994367199_-392642777","id":"20180707-161247_1834064283","dateCreated":"2018-07-07T16:12:47-0400","dateStarted":"2018-09-18T09:42:07-0400","dateFinished":"2018-09-18T09:42:10-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11036"},{"text":"spark.version","user":"anonymous","dateUpdated":"2018-09-18T00:16:55-0400","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res81: String = 2.1.0\n"}]},"apps":[],"jobName":"paragraph_1537242770343_657932378","id":"20180917-235250_1901962402","dateCreated":"2018-09-17T23:52:50-0400","dateStarted":"2018-09-18T00:16:55-0400","dateFinished":"2018-09-18T00:16:56-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11037"},{"title":"HDP Hive JDBC","text":"\nvar props = new java.util.Properties()\nprops.setProperty(\"driver\", \"org.apache.hive.jdbc.HiveDriver\")\nprops.setProperty(\"user\", \"hive\")\nprops.setProperty(\"password\", \"hive\")\nprops.setProperty(\"hive.resultset.use.unique.column.names\",\"false\")\n\n    \nval ds = spark.read.jdbc(\n  url=\"jdbc:hive2://ec2-18-205-157-203.compute-1.amazonaws.com:10000/default\",\n  table=s\"(select * from price_history_nyse) abc\",\n  properties=props )\n \n//ds.count\nds.printSchema \nds.show\n\n//dbc:hive2://ip-172-30-0-218.ec2.internal:10000/default\n\n","user":"anonymous","dateUpdated":"2018-11-02T20:49:21-0400","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.lang.NullPointerException\n\tat org.apache.zeppelin.spark.Utils.invokeMethod(Utils.java:38)\n\tat org.apache.zeppelin.spark.Utils.invokeMethod(Utils.java:33)\n\tat org.apache.zeppelin.spark.SparkInterpreter.createSparkContext_2(SparkInterpreter.java:398)\n\tat org.apache.zeppelin.spark.SparkInterpreter.createSparkContext(SparkInterpreter.java:387)\n\tat org.apache.zeppelin.spark.SparkInterpreter.getSparkContext(SparkInterpreter.java:146)\n\tat org.apache.zeppelin.spark.SparkInterpreter.open(SparkInterpreter.java:843)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.open(LazyOpenInterpreter.java:70)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:491)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:175)\n\tat org.apache.zeppelin.scheduler.FIFOScheduler$1.run(FIFOScheduler.java:139)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n"}]},"apps":[],"jobName":"paragraph_1537244215920_-683666256","id":"20180918-001655_371057560","dateCreated":"2018-09-18T00:16:55-0400","dateStarted":"2018-11-02T20:49:21-0400","dateFinished":"2018-11-02T20:49:27-0400","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:11038"},{"text":"spark.version\n","user":"anonymous","dateUpdated":"2018-11-02T20:56:41-0400","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.lang.NullPointerException\n\tat org.apache.zeppelin.spark.Utils.invokeMethod(Utils.java:38)\n\tat org.apache.zeppelin.spark.Utils.invokeMethod(Utils.java:33)\n\tat org.apache.zeppelin.spark.SparkInterpreter.createSparkContext_2(SparkInterpreter.java:398)\n\tat org.apache.zeppelin.spark.SparkInterpreter.createSparkContext(SparkInterpreter.java:387)\n\tat org.apache.zeppelin.spark.SparkInterpreter.getSparkContext(SparkInterpreter.java:146)\n\tat org.apache.zeppelin.spark.SparkInterpreter.open(SparkInterpreter.java:843)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.open(LazyOpenInterpreter.java:70)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:491)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:175)\n\tat org.apache.zeppelin.scheduler.FIFOScheduler$1.run(FIFOScheduler.java:139)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n"}]},"apps":[],"jobName":"paragraph_1541205762665_1378678557","id":"20181102-204242_1265681479","dateCreated":"2018-11-02T20:42:42-0400","dateStarted":"2018-11-02T20:56:41-0400","dateFinished":"2018-11-02T20:56:47-0400","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:11039"},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1541206601694_884284443","id":"20181102-205641_473188097","dateCreated":"2018-11-02T20:56:41-0400","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:11040"}],"name":"Owl / JDBC","id":"2DJ4TX9R1","angularObjects":{"2DFW5AMX7:shared_process":[],"2DG2GK25N:shared_process":[],"2DGRFFZMA:shared_process":[],"2DERM7RYU:shared_process":[],"2DFFH5QGT:shared_process":[],"2DF2PH329:shared_process":[],"2DF55VSFN:shared_process":[],"2DH2XWUQA:shared_process":[],"2DGHUQGA8:shared_process":[],"2DH9U1ABT:shared_process":[],"2DDPWP28H:shared_process":[],"2DEK5Z276:shared_process":[],"2DDTZ2MKK:shared_process":[],"2DGZQPS75:shared_process":[],"2DF6DQ2V6:shared_process":[],"2DDPQKAK4:shared_process":[],"2DDTQYJ7P:shared_process":[],"2DGCHXAN1:shared_process":[],"2DFDNF2GQ:shared_process":[],"2DHD7TD9C:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}